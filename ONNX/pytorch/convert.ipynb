{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "421841e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a61ce4",
   "metadata": {},
   "source": [
    "# Usage"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7f8e390c",
   "metadata": {},
   "source": [
    "Pytorch models can be converted to onnx by simply calling 'torch.onnx.export'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3b09e58",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function export in module torch.onnx:\n",
      "\n",
      "export(model, args, f, export_params=True, verbose=False, training=<TrainingMode.EVAL: 0>, input_names=None, output_names=None, aten=False, export_raw_ir=False, operator_export_type=None, opset_version=None, _retain_param_name=True, do_constant_folding=True, example_outputs=None, strip_doc_string=True, dynamic_axes=None, keep_initializers_as_inputs=None, custom_opsets=None, enable_onnx_checker=True, use_external_data_format=False)\n",
      "    Export a model into ONNX format.  This exporter runs your model\n",
      "    once in order to get a trace of its execution to be exported;\n",
      "    at the moment, it supports a limited set of dynamic models (e.g., RNNs.)\n",
      "    \n",
      "    Arguments:\n",
      "        model (torch.nn.Module): the model to be exported.\n",
      "        args (tuple of arguments or torch.Tensor): the inputs to\n",
      "            the model, e.g., such that ``model(*args)`` is a valid\n",
      "            invocation of the model.  Any non-Tensor arguments will\n",
      "            be hard-coded into the exported model; any Tensor arguments\n",
      "            will become inputs of the exported model, in the order they\n",
      "            occur in args.  If args is a Tensor, this is equivalent\n",
      "            to having called it with a 1-ary tuple of that Tensor.\n",
      "            (Note: passing keyword arguments to the model is not currently\n",
      "            supported.  Give us a shout if you need it.)\n",
      "        f: a file-like object (has to implement fileno that returns a file descriptor)\n",
      "            or a string containing a file name.  A binary Protobuf will be written\n",
      "            to this file.\n",
      "        export_params (bool, default True): if specified, all parameters will\n",
      "            be exported.  Set this to False if you want to export an untrained model.\n",
      "            In this case, the exported model will first take all of its parameters\n",
      "            as arguments, the ordering as specified by ``model.state_dict().values()``\n",
      "        verbose (bool, default False): if specified, we will print out a debug\n",
      "            description of the trace being exported.\n",
      "        training (enum, default TrainingMode.EVAL):\n",
      "            TrainingMode.EVAL: export the model in inference mode.\n",
      "            TrainingMode.PRESERVE: export the model in inference mode if model.training is\n",
      "            False and to a training friendly mode if model.training is True.\n",
      "            TrainingMode.TRAINING: export the model in a training friendly mode.\n",
      "        input_names(list of strings, default empty list): names to assign to the\n",
      "            input nodes of the graph, in order\n",
      "        output_names(list of strings, default empty list): names to assign to the\n",
      "            output nodes of the graph, in order\n",
      "        aten (bool, default False): [DEPRECATED. use operator_export_type] export the\n",
      "            model in aten mode. If using aten mode, all the ops original exported\n",
      "            by the functions in symbolic_opset<version>.py are exported as ATen ops.\n",
      "        export_raw_ir (bool, default False): [DEPRECATED. use operator_export_type]\n",
      "            export the internal IR directly instead of converting it to ONNX ops.\n",
      "        operator_export_type (enum, default OperatorExportTypes.ONNX):\n",
      "            OperatorExportTypes.ONNX: All ops are exported as regular ONNX ops\n",
      "            (with ONNX namespace).\n",
      "            OperatorExportTypes.ONNX_ATEN: All ops are exported as ATen ops\n",
      "            (with aten namespace).\n",
      "            OperatorExportTypes.ONNX_ATEN_FALLBACK: If an ATen op is not supported\n",
      "            in ONNX or its symbolic is missing, fall back on ATen op. Registered ops\n",
      "            are exported to ONNX regularly.\n",
      "            Example graph::\n",
      "    \n",
      "                graph(%0 : Float)::\n",
      "                  %3 : int = prim::Constant[value=0]()\n",
      "                  %4 : Float = aten::triu(%0, %3) # missing op\n",
      "                  %5 : Float = aten::mul(%4, %0) # registered op\n",
      "                  return (%5)\n",
      "    \n",
      "            is exported as::\n",
      "    \n",
      "                graph(%0 : Float)::\n",
      "                  %1 : Long() = onnx::Constant[value={0}]()\n",
      "                  %2 : Float = aten::ATen[operator=\"triu\"](%0, %1)  # missing op\n",
      "                  %3 : Float = onnx::Mul(%2, %0) # registered op\n",
      "                  return (%3)\n",
      "    \n",
      "            In the above example, aten::triu is not supported in ONNX, hence\n",
      "            exporter falls back on this op.\n",
      "            OperatorExportTypes.RAW: Export raw ir.\n",
      "            OperatorExportTypes.ONNX_FALLTHROUGH: If an op is not supported\n",
      "            in ONNX, fall through and export the operator as is, as a custom \n",
      "            ONNX op. Using this mode, the op can be exported and implemented by\n",
      "            the user for their runtime backend.\n",
      "            Example graph::\n",
      "    \n",
      "                graph(%x.1 : Long(1:1))::\n",
      "                  %1 : None = prim::Constant()\n",
      "                  %2 : Tensor = aten::sum(%x.1, %1)\n",
      "                  %y.1 : Tensor[] = prim::ListConstruct(%2)\n",
      "                  return (%y.1)\n",
      "    \n",
      "            is exported as::\n",
      "    \n",
      "                graph(%x.1 : Long(1:1))::\n",
      "                  %1 : Tensor = onnx::ReduceSum[keepdims=0](%x.1)\n",
      "                  %y.1 : Long() = prim::ListConstruct(%1)\n",
      "                  return (%y.1)\n",
      "    \n",
      "            In the above example, prim::ListConstruct is not supported, hence\n",
      "            exporter falls through.\n",
      "    \n",
      "        opset_version (int, default is 9): by default we export the model to the\n",
      "            opset version of the onnx submodule. Since ONNX's latest opset may\n",
      "            evolve before next stable release, by default we export to one stable\n",
      "            opset version. Right now, supported stable opset version is 9.\n",
      "            The opset_version must be _onnx_master_opset or in _onnx_stable_opsets\n",
      "            which are defined in torch/onnx/symbolic_helper.py\n",
      "        do_constant_folding (bool, default False): If True, the constant-folding\n",
      "            optimization is applied to the model during export. Constant-folding\n",
      "            optimization will replace some of the ops that have all constant\n",
      "            inputs, with pre-computed constant nodes.\n",
      "        example_outputs (tuple of Tensors, default None): Model's example outputs being exported.\n",
      "            example_outputs must be provided when exporting a ScriptModule or TorchScript Function.\n",
      "        strip_doc_string (bool, default True): if True, strips the field\n",
      "            \"doc_string\" from the exported model, which information about the stack\n",
      "            trace.\n",
      "        dynamic_axes (dict<string, dict<int, string>> or dict<string, list(int)>, default empty dict):\n",
      "            a dictionary to specify dynamic axes of input/output, such that:\n",
      "            - KEY:  input and/or output names\n",
      "            - VALUE: index of dynamic axes for given key and potentially the name to be used for\n",
      "            exported dynamic axes. In general the value is defined according to one of the following\n",
      "            ways or a combination of both:\n",
      "            (1). A list of integers specifying the dynamic axes of provided input. In this scenario\n",
      "            automated names will be generated and applied to dynamic axes of provided input/output\n",
      "            during export.\n",
      "            OR (2). An inner dictionary that specifies a mapping FROM the index of dynamic axis in\n",
      "            corresponding input/output TO the name that is desired to be applied on such axis of\n",
      "            such input/output during export.\n",
      "    \n",
      "            Example. if we have the following shape for inputs and outputs:\n",
      "    \n",
      "            .. code-block:: none\n",
      "    \n",
      "                shape(input_1) = ('b', 3, 'w', 'h')\n",
      "                and shape(input_2) = ('b', 4)\n",
      "                and shape(output)  = ('b', 'd', 5)\n",
      "    \n",
      "            Then `dynamic axes` can be defined either as:\n",
      "    \n",
      "            1. ONLY INDICES::\n",
      "    \n",
      "                ``dynamic_axes = {'input_1':[0, 2, 3],\n",
      "                                  'input_2':[0],\n",
      "                                  'output':[0, 1]}``\n",
      "                where automatic names will be generated for exported dynamic axes\n",
      "    \n",
      "            2. INDICES WITH CORRESPONDING NAMES::\n",
      "    \n",
      "                ``dynamic_axes = {'input_1':{0:'batch',\n",
      "                                             1:'width',\n",
      "                                             2:'height'},\n",
      "                                  'input_2':{0:'batch'},\n",
      "                                  'output':{0:'batch',\n",
      "                                            1:'detections'}``\n",
      "                where provided names will be applied to exported dynamic axes\n",
      "    \n",
      "            3. MIXED MODE OF (1) and (2)::\n",
      "    \n",
      "                ``dynamic_axes = {'input_1':[0, 2, 3],\n",
      "                                  'input_2':{0:'batch'},\n",
      "                                  'output':[0,1]}``\n",
      "    \n",
      "        keep_initializers_as_inputs (bool, default None): If True, all the\n",
      "            initializers (typically corresponding to parameters) in the\n",
      "            exported graph will also be added as inputs to the graph. If False,\n",
      "            then initializers are not added as inputs to the graph, and only\n",
      "            the non-parameter inputs are added as inputs.\n",
      "    \n",
      "            This may allow for better optimizations (such as constant folding\n",
      "            etc.) by backends/runtimes that execute these graphs. If\n",
      "            unspecified (default None), then the behavior is chosen\n",
      "            automatically as follows. If operator_export_type is\n",
      "            OperatorExportTypes.ONNX, the behavior is equivalent to setting\n",
      "            this argument to False. For other values of operator_export_type,\n",
      "            the behavior is equivalent to setting this argument to True. Note\n",
      "            that for ONNX opset version < 9, initializers MUST be part of graph\n",
      "            inputs. Therefore, if opset_version argument is set to a 8 or\n",
      "            lower, this argument will be ignored.\n",
      "        custom_opsets (dict<string, int>, default empty dict): A dictionary to indicate\n",
      "            custom opset domain and version at export. If model contains a custom opset,\n",
      "            it is optional to specify the domain and opset version in the dictionary:\n",
      "            - KEY: opset domain name\n",
      "            - VALUE: opset version\n",
      "            If the custom opset is not provided in this dictionary, opset version is set\n",
      "            to 1 by default.\n",
      "        enable_onnx_checker (bool, default True): If True the onnx model checker will be run\n",
      "            as part of the export, to ensure the exported model is a valid ONNX model.\n",
      "        external_data_format (bool, default False): If True, then the model is exported\n",
      "            in ONNX external data format, in which case some of the model parameters are stored\n",
      "            in external binary files and not in the ONNX model file itself. See link for format\n",
      "            details: \n",
      "            https://github.com/onnx/onnx/blob/8b3f7e2e7a0f2aba0e629e23d89f07c7fc0e6a5e/onnx/onnx.proto#L423\n",
      "            Also, in this case,  argument 'f' must be a string specifying the location of the model.\n",
      "            The external binary files will be stored in the same location specified by the model \n",
      "            location 'f'. If False, then the model is stored in regular format, i.e. model and\n",
      "            parameters are all in one file. This argument is ignored for all export types other\n",
      "            than ONNX.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.onnx.export)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2724d483",
   "metadata": {},
   "source": [
    "# export custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6ff6ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_onnx_path = './model/custom-model/model.onnx'\n",
    "os.makedirs(Path(custom_onnx_path).parent.absolute(), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "57af68b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lmy/anaconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "class CustomTorchModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # assume input size: (224, 224)\n",
    "        self.conv1 = torch.nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = torch.nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv4 = torch.nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.fc1 = torch.nn.Linear(12544, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #(3, 224, 224)\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        #(16, 112, 112)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        #(32, 56, 56)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        #(64, 28, 28)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(x)\n",
    "        #(64, 14, 14)\n",
    "        x = torch.flatten(x)\n",
    "        #(12544, )\n",
    "        x = self.fc1(x)\n",
    "        #(10, )\n",
    "        x = F.softmax(x)\n",
    "        return x\n",
    "    \n",
    "model = CustomTorchModel()\n",
    "dummy_input = torch.Tensor(np.random.random((1, 3, 224, 224)))\n",
    "torch.onnx.export(model, dummy_input, custom_onnx_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175ee681",
   "metadata": {},
   "source": [
    "# export pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efda4200",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_path = './model/pretrained-model/model.onnx'\n",
    "os.makedirs(Path(pretrained_model_path).parent.absolute(), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f5e86ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "dummy_input = torch.Tensor(np.random.random((1, 3, 224, 224)))\n",
    "torch.onnx.export(model, dummy_input, pretrained_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9301af5",
   "metadata": {},
   "source": [
    "# Inference all converted onnx models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2499fbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "import onnxruntime\n",
    "import onnx\n",
    "\n",
    "# since the model is converted from pytorch, the input image should be (B, C, H, W)\n",
    "# if the model is from tensorflow, then it should be (B, H, W, C)\n",
    "image = np.random.random((1, 3, 224, 224)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b79258de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model path = ./model/pretrained-model/model.onnx, result=111\n",
      "model path = ./model/custom-model/model.onnx, result=7\n"
     ]
    }
   ],
   "source": [
    "model_paths = glob('./model/**/*.onnx', recursive=True)\n",
    "for model_path in model_paths:\n",
    "    onnx_model = onnx.load(model_path)\n",
    "    sess = onnxruntime.InferenceSession(model_path)\n",
    "    result = sess.run(output_names=[onnx_model.graph.output[0].name], input_feed={onnx_model.graph.input[0].name: image})\n",
    "    result = np.argmax(result)\n",
    "    print('model path = {}, result={}'.format(model_path, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e42aec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
